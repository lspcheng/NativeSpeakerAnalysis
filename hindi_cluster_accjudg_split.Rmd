---
title: "Hindi: Acceptibility Judgment Clustering"
output: html_document
---
## Packages & Functions
```{r}
library(tidyverse)
library(mgsub)
library(ggplot2)

# Create tables
library(gt)
library(webshot)
library(webshot2)

# Clustering
library(cluster)
library(factoextra)
library(fpc)

gg_theme <- function() {
  theme_bw() +
  theme(plot.title=element_text(size=25),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=20),
        axis.text=element_text(size=15),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=15))+
  theme(legend.title = element_text(size=15, face="bold"),
        legend.text=element_text(size=10))
}
```

## Load in Data
```{r}
load(file="data/processed/hindi_groups.RData")
load(file="data/processed/hindi_accjudg.RData")
```

# .
## Cluster Analysis: (Un)Gram
```{r}
if (!dir.exists("output/accjudg_gram")) {
  dir.create("output/accjudg_gram") }
```

### Prep Data
```{r}
# Full F1-F2 vowel space
accjudg_gram_scores <- hindi_accjudg %>% select(-participant) %>% select(starts_with(c("gram", "ungram")))
accjudg_gram_scaled <- as.data.frame(lapply(accjudg_gram_scores, scale))
accjudg_gram_scaled
```

### Assess Clustering Tendency

```{r}
# Create and plot Random dataset to compare to actual
random_df <- apply(accjudg_gram_scores, 2, function(x){runif(length(x), min(x), (max(x)))})
random_df <- as.data.frame(random_df)
random_scaled <- as.data.frame(lapply(random_df, scale))
random_scaled

# Plot random dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(random_scaled), title = "PCA - Gram/Ungram Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```


```{r}
#### Visual Inspection
# Plot dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(accjudg_gram_scaled), title = "PCA - Gram/Ungram Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")

fviz_pca_ind(prcomp(accjudg_gram_scaled), title = "PCA - Gram/Ungram Response Data",
             habillage = hindi_groups$residence_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```

```{r}
# Check Hopkins statistics (above 0.5 is threshold)
res <- get_clust_tendency(accjudg_gram_scaled, n = nrow(accjudg_gram_scaled)-1, graph = FALSE)
res$hopkins_stat
```



### Assess Number of Clusters
```{r}
# Elbow method
fviz_nbclust(accjudg_gram_scaled, kmeans, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")

fviz_nbclust(accjudg_gram_scaled, hcut, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")
```


```{r}
# Silhouette method
fviz_nbclust(accjudg_gram_scaled, kmeans, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

fviz_nbclust(accjudg_gram_scaled, hcut, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

```


```{r}
# Gap statistic
# nboot = 50 to keep the function speedy. 
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
# fviz_nbclust(accjudg_gram_scaled, kmeans, nstart = 25,  method = "gap_stat", nboot = 500, k.max = 10)+
  # labs(subtitle = "Gap statistic method")

#calculate gap statistic for each number of clusters (up to 10 clusters)
gap_stat <- clusGap(accjudg_gram_scaled, FUN = hcut, nstart = 25, K.max = 10, B = 500)

#produce plot of clusters vs. gap statistic
fviz_gap_stat(gap_stat)
```

```{r}
# Calculate 30 different indices of cluster size and pick consensus
library(NbClust)

# NbClust(accjudg_gram_scaled, distance="euclidean", min.nc=2, max.nc=10, method="kmeans", index="all")

NbClust(accjudg_gram_scaled, distance="euclidean", min.nc=2, max.nc=10, method="ward.D2", index="all")
```

# .
### Run Hierarchical clustering

#### Test Runs
```{r}
#perform hierarchical clustering using Ward's minimum variance
set.seed(168)
clust <- agnes(accjudg_gram_scaled, method = "average")
clust

#produce dendrogram
# png(filename ="output/accjudg_gram_dendrogram.png")
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram") 
```

```{r}
#compute distance matrix
d <- dist(accjudg_gram_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
hclust_ward <- hclust(d, method = "ward.D2")
hclust_avg <- hclust(d, method = "average" )
hclust_cmp <- hclust(d, method = "complete")
hclust_sgl <- hclust(d, method = "single" )

```

```{r}
plot(hclust_ward)
plot(hclust_avg)
plot(hclust_cmp)
plot(hclust_sgl)
```

#### Final Run

```{r}
#compute distance matrix
d <- dist(accjudg_gram_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
final_clust <- hclust(d, method = "ward.D2")
```

```{r}
#cut the dendrogram into clusters
cluster <- cutree(final_clust, k=2)

#find number of observations in each cluster
table(cluster)
```

```{r}
png(filename = "output/accjudg_gram/accjudg_gram_clust_dendrogram.png", res = 300, width = 12, height = 7, units = 'in')
plot(final_clust)
rect.hclust(final_clust , k = 2, border = 2:6)
# abline(h = 13, col = 'red')
```


```{r}
# append cluster labels to original data
accjudg_gram_final_data <- cbind(hindi_groups, cluster = cluster) %>%
  cbind(accjudg_gram_scores)

# View(accjudg_gram_final_data)
```


##### Validate (Internal)
```{r}
# Silhouette Plot
# A large value (close to 1) represents good clustering; Close to -1 means bad (wrong cluster)
sil <- silhouette(cluster, dist(accjudg_gram_scaled))
fviz_silhouette(sil, palette="jco") + theme_bw()
```

```{r}
# Dunn Index
# A large Dunn index reprsents good clustering (min.separation/max.diamenter)
km.stats <- cluster.stats(dist(accjudg_gram_scaled), cluster)
km.stats$dunn
```

##### Validate (External)
```{r}
# 3-cluster v. Native

# How well do clusters match group structure?
native_groups <- as.numeric(as.factor(hindi_groups$native_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_gram_scaled), native_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(native_groups,cluster)
```

```{r}
# 3-cluster v. residence

# How well do clusters match group structure?
residence_groups <- as.numeric(as.factor(hindi_groups$residence_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_gram_scaled), residence_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(residence_groups,cluster)
```

```{r}
# Language Experience v. Current cluster

# How well do clusters match group structure?
clust.stats <- cluster.stats(d = dist(accjudg_gram_scaled), langexp_final_data$cluster3, accjudg_gram_final_data$cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(langexp_final_data$cluster3,accjudg_gram_final_data$cluster)
```

#### Data Summary
```{r}
# # Check cluster individuals
# accjudg_gram_final_data %>% filter(cluster==1)
# accjudg_gram_final_data %>% filter(cluster==2)
```


##### Count Tables
```{r}
# Count of smaller clusters within larger clusters
accjudg_gram_final_data %>% count(cluster) %>% pivot_wider(names_from = cluster, values_from=n)
```

```{r}
# 3-cluster table
cluster_counts <- 
  accjudg_gram_final_data %>% count(cluster) %>%
  merge(accjudg_gram_final_data %>% group_by(cluster) %>%
          count(native_group) %>% pivot_wider(names_from = native_group, values_from=n) 
        ) %>%
  merge(accjudg_gram_final_data %>% group_by(cluster) %>% 
          count(residence_group) %>% pivot_wider(names_from = residence_group, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "Category Counts by Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Native Identification",
    columns = c(both, Eng, HU, neither)
  ) %>%
  tab_spanner(
    label = "Residential History",
    columns = c(NorthAm, SAtoNA, SouthAs, uncategorized)
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = cell_borders(color = "lightgrey", sides = c("left"), weight = px(2)),
            locations = list(
              cells_column_spanners(),
              cells_column_labels(columns = NorthAm),
              cells_body(columns = NorthAm),
              cells_grand_summary(columns = NorthAm)
            )
            ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_gram/accjudg_gram_clust_counts.html")
webshot2::webshot("output/accjudg_gram/accjudg_gram_clust_counts.html", "output/accjudg_gram/accjudg_gram_clust_counts.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_gram_clust_counts.tex") 
```


```{r}
# LangExp by accjudg_gram
# 3-cluster table 
cluster_counts <- 
  accjudg_gram_final_data %>% count(cluster) %>%
  merge(accjudg_gram_final_data %>% 
          mutate(cluster_langexp = langexp_final_data$cluster3) %>%
          group_by(cluster) %>%  count(cluster_langexp) %>%
          pivot_wider(names_from = cluster_langexp, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "LangExp Cluster Counts by Grammaticality Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Language Experience Cluster",
    columns = c("1", "2", "3")
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_gram/accjudg_gram_clust_counts_langexp.html")
webshot2::webshot("output/accjudg_gram/accjudg_gram_clust_counts_langexp.html", "output/accjudg_gram/accjudg_gram_clust_counts_langexp.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_gram_clust_counts.tex") 
```


##### Cluster Plots
```{r}
# Plot clusters
fviz_cluster(list(data = accjudg_gram_scaled, cluster = cluster),
             ellipse.type = "norm", geom = "point", stand = FALSE,
             palette = "jco") + gg_theme() +
  labs(fill = "Cluster", color = "Cluster", shape = "Cluster")
ggsave("./output/accjudg_gram/accjudg_gram_clust_cluster.png")

```


##### Z-Mean Plots
```{r}
# Z-score effect Cluster results
hindi_groups %>% cbind(cluster) %>%
  cbind(accjudg_gram_scaled) %>% group_by(cluster) %>% summarize(across(where(is.numeric), mean)) %>%
  pivot_longer(gram_long:last_col(), names_to = "condition", values_to = "z_score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=z_score, fill=condition)) +
  geom_bar(stat="identity", position="dodge", alpha=0.8) +
  labs(subtitle="Cluster Z-Means", x="Cluster", y="Z-Score", color="Variable", fill="Variable") +
  facet_wrap(~cluster) +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))


ggsave("output/accjudg_gram/accjudg_gram_clust_zmeans.png", width=12, height=7)
```

##### Mean Tables
```{r}
cluster_means <- accjudg_gram_final_data %>% group_by(cluster) %>% 
  summarize(across(where(is.numeric), mean))
cluster_means
```

##### Mean Plots
```{r}
cluster.plt <- 
  cluster_means %>% 
  pivot_longer(gram_long:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=score, fill=condition)) +
  geom_col(position="dodge", width=0.8, alpha=0.8) +
  facet_wrap(~cluster) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))
cluster.plt

ggsave("output/accjudg_gram/accjudg_gram_clust_means.png", width=12, height=7)
```


##### Individual Plots
```{r}
# # Cluster results by individual
accjudg_gram_final_data %>%
  pivot_longer(gram_long:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%

  ggplot(aes(x=condition, y=score, fill=condition, color=condition, alpha=participant)) +
  geom_col(position="dodge", width=0.8) +
  facet_wrap(~cluster, ncol=4) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  scale_alpha_discrete(guide = "none") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))

ggsave("output/accjudg_gram/accjudg_gram_clust_ind.png", width=12, height=7)


```


# .
## Cluster Analysis: Word Order
```{r}
if (!dir.exists("output/accjudg_order")) {
  dir.create("output/accjudg_order") }
```

### Prep Data
```{r}
# Full F1-F2 vowel space
accjudg_order_scores <- hindi_accjudg %>% select(-participant) %>% select(starts_with(c("s", "o", "v")))
accjudg_order_scaled <- as.data.frame(lapply(accjudg_order_scores, scale))
accjudg_order_scaled
```

### Assess Clustering Tendency

```{r}
# Create and plot Random dataset to compare to actual
random_df <- apply(accjudg_order_scores, 2, function(x){runif(length(x), min(x), (max(x)))})
random_df <- as.data.frame(random_df)
random_scaled <- as.data.frame(lapply(random_df, scale))
random_scaled

# Plot random dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(random_scaled), title = "PCA - Word Order Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```


```{r}
#### Visual Inspection
# Plot dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(accjudg_order_scaled), title = "PCA - Word Order Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")

fviz_pca_ind(prcomp(accjudg_order_scaled), title = "PCA - Word Order Response Data",
             habillage = hindi_groups$residence_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```

```{r}
# Check Hopkins statistics (above 0.5 is threshold)
res <- get_clust_tendency(accjudg_order_scaled, n = nrow(accjudg_order_scaled)-1, graph = FALSE)
res$hopkins_stat
```



### Assess Number of Clusters
```{r}
# Elbow method
fviz_nbclust(accjudg_order_scaled, kmeans, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")

fviz_nbclust(accjudg_order_scaled, hcut, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")
```


```{r}
# Silhouette method
fviz_nbclust(accjudg_order_scaled, kmeans, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

fviz_nbclust(accjudg_order_scaled, hcut, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

```


```{r}
# Gap statistic
# nboot = 50 to keep the function speedy. 
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
# fviz_nbclust(accjudg_order_scaled, kmeans, nstart = 25,  method = "gap_stat", nboot = 500, k.max = 10)+
  # labs(subtitle = "Gap statistic method")

#calculate gap statistic for each number of clusters (up to 10 clusters)
gap_stat <- clusGap(accjudg_order_scaled, FUN = hcut, nstart = 25, K.max = 10, B = 500)

#produce plot of clusters vs. gap statistic
fviz_gap_stat(gap_stat)
```

```{r}
# Calculate 30 different indices of cluster size and pick consensus
library(NbClust)

# NbClust(accjudg_order_scaled, distance="euclidean", min.nc=2, max.nc=10, method="kmeans", index="all")

NbClust(accjudg_order_scaled, distance="euclidean", min.nc=2, max.nc=10, method="ward.D2", index="all")
```

# .
### Run Hierarchical clustering

#### Test Runs
```{r}
#perform hierarchical clustering using Ward's minimum variance
set.seed(168)
clust <- agnes(accjudg_order_scaled, method = "average")
clust

#produce dendrogram
# png(filename ="output/accjudg_order_dendrogram.png")
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram") 
```

```{r}
#compute distance matrix
d <- dist(accjudg_order_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
hclust_ward <- hclust(d, method = "ward.D2")
hclust_avg <- hclust(d, method = "average" )
hclust_cmp <- hclust(d, method = "complete")
hclust_sgl <- hclust(d, method = "single" )

```

```{r}
plot(hclust_ward)
plot(hclust_avg)
plot(hclust_cmp)
plot(hclust_sgl)
```

#### Final Run

```{r}
#compute distance matrix
d <- dist(accjudg_order_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
final_clust <- hclust(d, method = "ward.D2")
```

```{r}
#cut the dendrogram into clusters
cluster <- cutree(final_clust, k=2)

#find number of observations in each cluster
table(cluster)
```

```{r}
png(filename = "output/accjudg_order/accjudg_order_clust_dendrogram.png", res = 300, width = 12, height = 7, units = 'in')
plot(final_clust)
rect.hclust(final_clust , k = 2, border = 2:6)
# abline(h = 13, col = 'red')
```


```{r}
# append cluster labels to original data
accjudg_order_final_data <- cbind(hindi_groups, cluster = cluster) %>%
  cbind(accjudg_order_scores)

# View(accjudg_order_final_data)
```


##### Validate (Internal)
```{r}
# Silhouette Plot
# A large value (close to 1) represents good clustering; Close to -1 means bad (wrong cluster)
sil <- silhouette(cluster, dist(accjudg_order_scaled))
fviz_silhouette(sil, palette="jco") + theme_bw()
```

```{r}
# Dunn Index
# A large Dunn index reprsents good clustering (min.separation/max.diamenter)
km.stats <- cluster.stats(dist(accjudg_order_scaled), cluster)
km.stats$dunn
```

##### Validate (External)
```{r}
# 3-cluster v. Native

# How well do clusters match group structure?
native_groups <- as.numeric(as.factor(hindi_groups$native_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_order_scaled), native_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(native_groups,cluster)
```

```{r}
# 3-cluster v. residence

# How well do clusters match group structure?
residence_groups <- as.numeric(as.factor(hindi_groups$residence_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_order_scaled), residence_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(residence_groups,cluster)
```

```{r}
# Language Experience v. Current cluster

# How well do clusters match group structure?
clust.stats <- cluster.stats(d = dist(accjudg_order_scaled), langexp_final_data$cluster3, accjudg_order_final_data$cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(langexp_final_data$cluster3,accjudg_order_final_data$cluster)
```

#### Data Summary
```{r}
# # Check cluster individuals
# accjudg_order_final_data %>% filter(cluster==1)
# accjudg_order_final_data %>% filter(cluster==2)
```


##### Count Tables
```{r}
# Count of smaller clusters within larger clusters
accjudg_order_final_data %>% count(cluster) %>% pivot_wider(names_from = cluster, values_from=n)
```

```{r}
# 3-cluster table
cluster_counts <- 
  accjudg_order_final_data %>% count(cluster) %>%
  merge(accjudg_order_final_data %>% group_by(cluster) %>%
          count(native_group) %>% pivot_wider(names_from = native_group, values_from=n) 
        ) %>%
  merge(accjudg_order_final_data %>% group_by(cluster) %>% 
          count(residence_group) %>% pivot_wider(names_from = residence_group, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "Category Counts by Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Native Identification",
    columns = c(both, Eng, HU, neither)
  ) %>%
  tab_spanner(
    label = "Residential History",
    columns = c(NorthAm, SAtoNA, SouthAs, uncategorized)
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = cell_borders(color = "lightgrey", sides = c("left"), weight = px(2)),
            locations = list(
              cells_column_spanners(),
              cells_column_labels(columns = NorthAm),
              cells_body(columns = NorthAm),
              cells_grand_summary(columns = NorthAm)
            )
            ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_order/accjudg_order_clust_counts.html")
webshot2::webshot("output/accjudg_order/accjudg_order_clust_counts.html", "output/accjudg_order/accjudg_order_clust_counts.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_order_clust_counts.tex") 
```


```{r}
# LangExp by accjudg_order
# 3-cluster table 
cluster_counts <- 
  accjudg_order_final_data %>% count(cluster) %>%
  merge(accjudg_order_final_data %>% 
          mutate(cluster_langexp = langexp_final_data$cluster3) %>%
          group_by(cluster) %>%  count(cluster_langexp) %>%
          pivot_wider(names_from = cluster_langexp, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "LangExp Cluster Counts by Word Order Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Language Experience Cluster",
    columns = c("1", "2", "3")
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_order/accjudg_order_clust_counts_langexp.html")
webshot2::webshot("output/accjudg_order/accjudg_order_clust_counts_langexp.html", "output/accjudg_order/accjudg_order_clust_counts_langexp.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_order_clust_counts.tex") 
```


##### Cluster Plots
```{r}
# Plot clusters
fviz_cluster(list(data = accjudg_order_scaled, cluster = cluster),
             ellipse.type = "norm", geom = "point", stand = FALSE,
             palette = "jco") + gg_theme() +
  labs(fill = "Cluster", color = "Cluster", shape = "Cluster")
ggsave("./output/accjudg_order/accjudg_order_clust_cluster.png")

```


##### Z-Mean Plots
```{r}
# Z-score effect Cluster results
hindi_groups %>% cbind(cluster) %>%
  cbind(accjudg_order_scaled) %>% group_by(cluster) %>% summarize(across(where(is.numeric), mean)) %>%
  pivot_longer(sov:last_col(), names_to = "condition", values_to = "z_score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=z_score, fill=condition)) +
  geom_bar(stat="identity", position="dodge", alpha=0.8) +
  labs(subtitle="Cluster Z-Means", x="Cluster", y="Z-Score", color="Variable", fill="Variable") +
  facet_wrap(~cluster) +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))


ggsave("output/accjudg_order/accjudg_order_clust_zmeans.png", width=12, height=7)
```

##### Mean Tables
```{r}
cluster_means <- accjudg_order_final_data %>% group_by(cluster) %>% 
  summarize(across(where(is.numeric), mean))
cluster_means
```

##### Mean Plots
```{r}
cluster.plt <- 
  cluster_means %>% 
  pivot_longer(sov:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=score, fill=condition)) +
  geom_col(position="dodge", width=0.8, alpha=0.8) +
  facet_wrap(~cluster) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))
cluster.plt

ggsave("output/accjudg_order/accjudg_order_clust_means.png", width=12, height=7)
```


##### Individual Plots
```{r}
# # Cluster results by individual
accjudg_order_final_data %>%
  pivot_longer(sov:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%

  ggplot(aes(x=condition, y=score, fill=condition, color=condition, alpha=participant)) +
  geom_col(position="dodge", width=0.8) +
  facet_wrap(~cluster, ncol=4) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  scale_alpha_discrete(guide = "none") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))

ggsave("output/accjudg_order/accjudg_order_clust_ind.png", width=12, height=7)


```


# .
## Cluster Analysis: PP
```{r}
if (!dir.exists("output/accjudg_prep")) {
  dir.create("output/accjudg_prep") }
```

### Prep Data
```{r}
# Full F1-F2 vowel space
accjudg_prep_scores <- hindi_accjudg %>% select(-participant) %>% select(starts_with(c("pp")))
accjudg_prep_scaled <- as.data.frame(lapply(accjudg_prep_scores, scale))
accjudg_prep_scaled
```

### Assess Clustering Tendency

```{r}
# Create and plot Random dataset to compare to actual
random_df <- apply(accjudg_prep_scores, 2, function(x){runif(length(x), min(x), (max(x)))})
random_df <- as.data.frame(random_df)
random_scaled <- as.data.frame(lapply(random_df, scale))
random_scaled

# Plot random dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(random_scaled), title = "PCA - PP Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```


```{r}
#### Visual Inspection
# Plot dataset with PCA to reduce dimensions to 2
fviz_pca_ind(prcomp(accjudg_prep_scaled), title = "PCA - PP Response Data",
             habillage = hindi_groups$native_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")

fviz_pca_ind(prcomp(accjudg_prep_scaled), title = "PCA - PP Response Data",
             habillage = hindi_groups$residence_group,  palette = "jco",
             geom = "point", ggtheme = theme_classic(),
             legend = "bottom")
```

```{r}
# Check Hopkins statistics (above 0.5 is threshold)
res <- get_clust_tendency(accjudg_prep_scaled, n = nrow(accjudg_prep_scaled)-1, graph = FALSE)
res$hopkins_stat
```



### Assess Number of Clusters
```{r}
# Elbow method
fviz_nbclust(accjudg_prep_scaled, kmeans, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")

fviz_nbclust(accjudg_prep_scaled, hcut, method = "wss", k.max = 10) +
  labs(subtitle = "Elbow method")
```


```{r}
# Silhouette method
fviz_nbclust(accjudg_prep_scaled, kmeans, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

fviz_nbclust(accjudg_prep_scaled, hcut, method = "silhouette", k.max = 10) +
  labs(subtitle = "Silhouette method")

```


```{r}
# Gap statistic
# nboot = 50 to keep the function speedy. 
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
# fviz_nbclust(accjudg_prep_scaled, kmeans, nstart = 25,  method = "gap_stat", nboot = 500, k.max = 10)+
  # labs(subtitle = "Gap statistic method")

#calculate gap statistic for each number of clusters (up to 10 clusters)
gap_stat <- clusGap(accjudg_prep_scaled, FUN = hcut, nstart = 25, K.max = 10, B = 500)

#produce plot of clusters vs. gap statistic
fviz_gap_stat(gap_stat)
```

```{r}
# Calculate 30 different indices of cluster size and pick consensus
library(NbClust)

# NbClust(accjudg_prep_scaled, distance="euclidean", min.nc=2, max.nc=10, method="kmeans", index="all")

NbClust(accjudg_prep_scaled, distance="euclidean", min.nc=2, max.nc=10, method="ward.D2", index="all")
```

# .
### Run Hierarchical clustering

#### Test Runs
```{r}
#perform hierarchical clustering using Ward's minimum variance
set.seed(168)
clust <- agnes(accjudg_prep_scaled, method = "average")
clust

#produce dendrogram
# png(filename ="output/accjudg_prep_dendrogram.png")
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram") 
```

```{r}
#compute distance matrix
d <- dist(accjudg_prep_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
hclust_ward <- hclust(d, method = "ward.D2")
hclust_avg <- hclust(d, method = "average" )
hclust_cmp <- hclust(d, method = "complete")
hclust_sgl <- hclust(d, method = "single" )

```

```{r}
plot(hclust_ward)
plot(hclust_avg)
plot(hclust_cmp)
plot(hclust_sgl)
```

#### Final Run

```{r}
#compute distance matrix
d <- dist(accjudg_prep_scaled, method = "euclidean")

#perform hierarchical clustering using Ward's method
set.seed(168)
final_clust <- hclust(d, method = "ward.D2")
```

```{r}
#cut the dendrogram into clusters
cluster <- cutree(final_clust, k=3)

#find number of observations in each cluster
table(cluster)
```

```{r}
png(filename = "output/accjudg_prep/accjudg_prep_clust_dendrogram.png", res = 300, width = 12, height = 7, units = 'in')
plot(final_clust)
rect.hclust(final_clust , k = 3, border = 2:6)
# abline(h = 13, col = 'red')
```


```{r}
# append cluster labels to original data
accjudg_prep_final_data <- cbind(hindi_groups, cluster = cluster) %>%
  cbind(accjudg_prep_scores)

# View(accjudg_prep_final_data)
```


##### Validate (Internal)
```{r}
# Silhouette Plot
# A large value (close to 1) represents good clustering; Close to -1 means bad (wrong cluster)
sil <- silhouette(cluster, dist(accjudg_prep_scaled))
fviz_silhouette(sil, palette="jco") + theme_bw()
```

```{r}
# Dunn Index
# A large Dunn index reprsents good clustering (min.separation/max.diamenter)
km.stats <- cluster.stats(dist(accjudg_prep_scaled), cluster)
km.stats$dunn
```

##### Validate (External)
```{r}
# 3-cluster v. Native

# How well do clusters match group structure?
native_groups <- as.numeric(as.factor(hindi_groups$native_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_prep_scaled), native_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(native_groups,cluster)
```

```{r}
# 3-cluster v. residence

# How well do clusters match group structure?
residence_groups <- as.numeric(as.factor(hindi_groups$residence_group)) 
clust.stats <- cluster.stats(d = dist(accjudg_prep_scaled), residence_groups,cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(residence_groups,cluster)
```

```{r}
# Language Experience v. Current cluster

# How well do clusters match group structure?
clust.stats <- cluster.stats(d = dist(accjudg_prep_scaled), langexp_final_data$cluster3, accjudg_prep_final_data$cluster)

# Corrected Rand Index
# Between 0 and 1, should be maximized (close to 1)
clust.stats$corrected.rand

# Meila's Variation of Information (VI)
# Closely related to mutual information. Should be minimized
clust.stats$vi

# Normalized Variation of Information (NVI) --- between 0 and 1
## NVI is zero if the partitions are identical and one if they are statistically independent, meaning no information is gained about C by knowing C′ and vice versa (Esmailian & Jaili, 2015)
aricode::NVI(langexp_final_data$cluster3,accjudg_prep_final_data$cluster)
```

#### Data Summary
```{r}
# # Check cluster individuals
# accjudg_prep_final_data %>% filter(cluster==1)
# accjudg_prep_final_data %>% filter(cluster==2)
```


##### Count Tables
```{r}
# Count of smaller clusters within larger clusters
accjudg_prep_final_data %>% count(cluster) %>% pivot_wider(names_from = cluster, values_from=n)
```

```{r}
# 3-cluster table
cluster_counts <- 
  accjudg_prep_final_data %>% count(cluster) %>%
  merge(accjudg_prep_final_data %>% group_by(cluster) %>%
          count(native_group) %>% pivot_wider(names_from = native_group, values_from=n) 
        ) %>%
  merge(accjudg_prep_final_data %>% group_by(cluster) %>% 
          count(residence_group) %>% pivot_wider(names_from = residence_group, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "Category Counts by Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Native Identification",
    columns = c(both, Eng, HU, neither)
  ) %>%
  tab_spanner(
    label = "Residential History",
    columns = c(NorthAm, SAtoNA, SouthAs, uncategorized)
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = cell_borders(color = "lightgrey", sides = c("left"), weight = px(2)),
            locations = list(
              cells_column_spanners(),
              cells_column_labels(columns = NorthAm),
              cells_body(columns = NorthAm),
              cells_grand_summary(columns = NorthAm)
            )
            ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_prep/accjudg_prep_clust_counts.html")
webshot2::webshot("output/accjudg_prep/accjudg_prep_clust_counts.html", "output/accjudg_prep/accjudg_prep_clust_counts.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_prep_clust_counts.tex") 
```


```{r}
# LangExp by accjudg_prep
# 3-cluster table 
cluster_counts <- 
  accjudg_prep_final_data %>% count(cluster) %>%
  merge(accjudg_prep_final_data %>% 
          mutate(cluster_langexp = langexp_final_data$cluster3) %>%
          group_by(cluster) %>%  count(cluster_langexp) %>%
          pivot_wider(names_from = cluster_langexp, values_from=n)
        ) %>%
  mutate(across(where(is.numeric), ~ coalesce(.x, 0))) %>%
  rename(Cluster = cluster) %>%
  
  as_tibble() %>%
  gt(rowname_col = "Cluster") %>%
  tab_header(
    title = "LangExp Cluster Counts by Word Order Cluster",
    subtitle = "2-cluster solution via hierarchical clustering"
  ) %>%
  fmt_integer(
    columns = everything()
  ) %>%
  tab_stubhead(label = "Cluster") %>%
  tab_spanner(
    label = "Language Experience Cluster",
    columns = c("1", "2", "3")
  ) %>%
  grand_summary_rows(
    columns = everything(),
    fns = list(
      Sum = ~sum(., na.rm=TRUE)),
    missing_text = "NA",
    formatter = fmt_integer
  ) %>%
  cols_align(align = c("center"),
             columns = everything()
             # columns = n
  ) %>%
  tab_style(style = list(
    cell_borders(color = "lightgrey", sides = c("left", "right"), weight = px(2)),
    cell_text(style = "italic")
    ), 
            locations = list(
              cells_column_labels(columns = n),
              cells_body(columns = n),
              cells_grand_summary(columns = n)
              )
            ) %>%
  tab_style(style = cell_text(weight="bold"), 
            locations = list(
              cells_title(groups= "title"),
              cells_column_spanners(),
              cells_stubhead(),
              cells_grand_summary(columns = everything(), rows = TRUE)
              )
            )
cluster_counts

gtsave(cluster_counts, "output/accjudg_prep/accjudg_prep_clust_counts_langexp.html")
webshot2::webshot("output/accjudg_prep/accjudg_prep_clust_counts_langexp.html", "output/accjudg_prep/accjudg_prep_clust_counts_langexp.png", vwidth = 625, zoom = 2.5) 
# gtsave(cluster_counts3, "output/latex/accjudg_prep_clust_counts.tex") 
```


##### Cluster Plots
```{r}
# Plot clusters
fviz_cluster(list(data = accjudg_prep_scaled, cluster = cluster),
             ellipse.type = "norm", geom = "point", stand = FALSE,
             palette = "jco") + gg_theme() +
  labs(fill = "Cluster", color = "Cluster", shape = "Cluster")
ggsave("./output/accjudg_prep/accjudg_prep_clust_cluster.png")

```


##### Z-Mean Plots
```{r}
# Z-score effect Cluster results
hindi_groups %>% cbind(cluster) %>%
  cbind(accjudg_prep_scaled) %>% group_by(cluster) %>% summarize(across(where(is.numeric), mean)) %>%
  pivot_longer(pp_ll:last_col(), names_to = "condition", values_to = "z_score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=z_score, fill=condition)) +
  geom_bar(stat="identity", position="dodge", alpha=0.8) +
  labs(subtitle="Cluster Z-Means", x="Cluster", y="Z-Score", color="Variable", fill="Variable") +
  facet_wrap(~cluster) +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))


ggsave("output/accjudg_prep/accjudg_prep_clust_zmeans.png", width=12, height=7)
```

##### Mean Tables
```{r}
cluster_means <- accjudg_prep_final_data %>% group_by(cluster) %>% 
  summarize(across(where(is.numeric), mean))
cluster_means
```

##### Mean Plots
```{r}
cluster.plt <- 
  cluster_means %>% 
  pivot_longer(pp_ll:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%
  
  ggplot(aes(x=condition, y=score, fill=condition)) +
  geom_col(position="dodge", width=0.8, alpha=0.8) +
  facet_wrap(~cluster) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))
cluster.plt

ggsave("output/accjudg_prep/accjudg_prep_clust_means.png", width=12, height=7)
```


##### Individual Plots
```{r}
# # Cluster results by individual
accjudg_prep_final_data %>%
  pivot_longer(pp_ll:last_col(), names_to = "condition", values_to = "score") %>%
  mutate(condition = factor(condition, levels = c("sov", "osv", "svo", "ovs", "vso", "vos", "pp_ss", "pp_ls", "pp_sl", "pp_ll", "gram_long", "gram_question", "ungram_gender", "ungram_sv", "ungram_tense"))) %>%

  ggplot(aes(x=condition, y=score, fill=condition, color=condition, alpha=participant)) +
  geom_col(position="dodge", width=0.8) +
  facet_wrap(~cluster, ncol=4) +
  labs(x="Cluster", y="Mean Rating Score", fill="Variable", color="Variable") +
  scale_alpha_discrete(guide = "none") +
  gg_theme() +
  # scale_fill_brewer(palette = "Paired") + 
  # scale_color_brewer(palette = "Paired") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  theme(legend.position = "bottom", legend.key.size = unit(.5, "cm"), legend.text = element_text(size=15))

ggsave("output/accjudg_prep/accjudg_prep_clust_ind.png", width=12, height=7)


```
